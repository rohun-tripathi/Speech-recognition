{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mohit/Box Sync/AudioCaptcha/Code/stt_code\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydub'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cf28b0ff8c9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maudio1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"broke.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydub'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# lib\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "audio1 = AudioSegment.from_file(\"broke.wav\", \"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.0 |Anaconda 4.3.1 (x86_64)| (default, Dec 23 2016, 13:19:00) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. Concatenate or combine or join two flac files\n",
    "# 2. Overlap two flac files\n",
    "# 3. Break an audio file in two parts\n",
    "# 4. Speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spear.flac'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6149bc14c66d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Try 1: Work on Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maudio1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spear.flac\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maudio2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"riflecock-3.flac\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maudioJoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maudio2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maudioFinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"audioFinal.flac\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudioJoin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spear.flac'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#Try 1: Work on Python 3.\n",
    "audio1 = open(\"spear.flac\", \"rb\").read()\n",
    "audio2 = open(\"riflecock-3.flac\", \"rb\").read()\n",
    "audioJoin = audio1 + audio2\n",
    "audioFinal = open(\"audioFinal.flac\", \"wb\").write(audioJoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# pip install pydub\n",
    "# pydub: https://github.com/jiaaro/pydub\n",
    "# Good example code with pydub: http://stackoverflow.com/questions/36632511/split-audio-file-into-several-files-each-below-a-size-threshold\n",
    "from pydub import AudioSegment\n",
    "\n",
    "#Read flac files\n",
    "audio1 = AudioSegment.from_file(\"mockingbird_3.wav\", \"wav\");\n",
    "audio2 = AudioSegment.from_file(\"mockingbird_3.wav\", \"wav\");\n",
    "\n",
    "# Split the audio file\n",
    "two_seconds = 2 * 1000\n",
    "first_2_seconds = audio1[:two_seconds]\n",
    "last_1_seconds = audio1[-1000:]\n",
    "\n",
    "# Concatenate the audio files\n",
    "result = first_2_seconds + audio2 + last_1_seconds\n",
    "\n",
    "# Write the audio as wav file\n",
    "# TODO: Somehow writing the audio in flac format is throwing error\n",
    "#result.export(\"audioFinal.wav\", format=\"wav\")\n",
    "\n",
    "# Detect silence and split based on that\n",
    "from pydub.silence import split_on_silence\n",
    "chunks = split_on_silence(audio1, \n",
    "    # must be silent for at least half a second\n",
    "    min_silence_len=100, #defaults: 500\n",
    "\n",
    "    # consider it silent if quieter than -16 dBFS\n",
    "    silence_thresh=-32 #default: -16\n",
    ")\n",
    "\n",
    "# Write the chunks of the file\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.export(\"broke.wav\".format(i), format=\"wav\")\n",
    "\n",
    "# Combine two files overlaying each other, rather than concatenating    \n",
    "combined = audio1.overlay(audio2)\n",
    "combined.export(\"combined.wav\", format='wav')\n",
    "print(\"Done\")\n",
    "\n",
    "audio3 = AudioSegment.from_file(\"1945-03-25_BBC_Robert_Barr_Reports_Winston_Churchill_Crosses_The_Rhine.mp3\", \"mp3\");\n",
    "audio3.export('1945-03-25_BBC_Robert_Barr_Reports_Winston_Churchill_Crosses_The_Rhine.wav', format='wav');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started 0\n",
      "Started 1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spear.flac'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dc1e5e1c931a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Started 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUDIO_FILE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# read the entire audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;31m# attempt to read the file as WAV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename_or_fileobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlittle_endian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/wave.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/wave.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# else, assume it is an open file object already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spear.flac'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# pip install SpeechRecognition\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "# obtain path to \"english.wav\" in the same folder as this script\n",
    "from os import path\n",
    "\n",
    "AUDIO_FILE = \"spear.flac\"\n",
    "#AUDIO_FILE = path.join(path.dirname(path.realpath(__file__)), \"spear.flac\")\n",
    "#AUDIO_FILE = path.join(path.dirname(path.realpath(__file__)), \"french.aiff\")\n",
    "#AUDIO_FILE = path.join(path.dirname(path.realpath(__file__)), \"chinese.flac\")\n",
    "\n",
    "# use the audio file as the audio source\n",
    "print(\"Started 0\");\n",
    "r = sr.Recognizer()\n",
    "print(\"Started 1\");\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "    audio = r.record(source) # read the entire audio file\n",
    "\n",
    "print(\"Started 2\");\n",
    "    \n",
    "# recognize speech using Sphinx\n",
    "try:\n",
    "    print(\"Sphinx thinks you said \" + r.recognize_sphinx(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sphinx could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Sphinx error; {0}\".format(e))\n",
    "\n",
    "# recognize speech using Google Speech Recognition\n",
    "try:\n",
    "    # for testing purposes, we're just using the default API key\n",
    "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "    # instead of `r.recognize_google(audio)`\n",
    "    print(\"Google Speech Recognition thinks you said \" + r.recognize_google(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "# recognize speech using Google Cloud Speech\n",
    "GOOGLE_CLOUD_SPEECH_CREDENTIALS = r\"\"\"INSERT THE CONTENTS OF THE GOOGLE CLOUD SPEECH JSON CREDENTIALS FILE HERE\"\"\"\n",
    "try:\n",
    "    print(\"Google Cloud Speech thinks you said \" + r.recognize_google_cloud(audio, credentials_json=GOOGLE_CLOUD_SPEECH_CREDENTIALS))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Cloud Speech could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Cloud Speech service; {0}\".format(e))\n",
    "\n",
    "# recognize speech using Wit.ai\n",
    "WIT_AI_KEY = \"INSERT WIT.AI API KEY HERE\" # Wit.ai keys are 32-character uppercase alphanumeric strings\n",
    "try:\n",
    "    print(\"Wit.ai thinks you said \" + r.recognize_wit(audio, key=WIT_AI_KEY))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Wit.ai could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Wit.ai service; {0}\".format(e))\n",
    "\n",
    "# recognize speech using Microsoft Bing Voice Recognition\n",
    "BING_KEY = \"INSERT BING API KEY HERE\" # Microsoft Bing Voice Recognition API keys 32-character lowercase hexadecimal strings\n",
    "try:\n",
    "    print(\"Microsoft Bing Voice Recognition thinks you said \" + r.recognize_bing(audio, key=BING_KEY))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Microsoft Bing Voice Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Microsoft Bing Voice Recognition service; {0}\".format(e))\n",
    "\n",
    "# recognize speech using Houndify\n",
    "HOUNDIFY_CLIENT_ID = \"INSERT HOUNDIFY CLIENT ID HERE\" # Houndify client IDs are Base64-encoded strings\n",
    "HOUNDIFY_CLIENT_KEY = \"INSERT HOUNDIFY CLIENT KEY HERE\" # Houndify client keys are Base64-encoded strings\n",
    "try:\n",
    "    print(\"Houndify thinks you said \" + r.recognize_houndify(audio, client_id=HOUNDIFY_CLIENT_ID, client_key=HOUNDIFY_CLIENT_KEY))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Houndify could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Houndify service; {0}\".format(e))\n",
    "\n",
    "# recognize speech using IBM Speech to Text\n",
    "IBM_USERNAME = \"INSERT IBM SPEECH TO TEXT USERNAME HERE\" # IBM Speech to Text usernames are strings of the form XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n",
    "IBM_PASSWORD = \"INSERT IBM SPEECH TO TEXT PASSWORD HERE\" # IBM Speech to Text passwords are mixed-case alphanumeric strings\n",
    "try:\n",
    "    print(\"IBM Speech to Text thinks you said \" + r.recognize_ibm(audio, username=IBM_USERNAME, password=IBM_PASSWORD))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"IBM Speech to Text could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from IBM Speech to Text service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import csv\n",
    "import json\n",
    "\n",
    "import scipy.io.wavfile as wv\n",
    "import speech_recognition as sr\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "MAX_DIFFICULTY = 3\n",
    "\n",
    "MIN_SILENCE_LIST_DEFAULT = [100, 200, 500]\n",
    "\n",
    "try:  # attempt to use the Python 2 modules\n",
    "    from urllib import urlencode\n",
    "    from urllib2 import Request, urlopen, URLError, HTTPError\n",
    "except ImportError:  # use the Python 3 modules\n",
    "    from urllib.parse import urlencode\n",
    "    from urllib.request import Request, urlopen\n",
    "    from urllib.error import URLError, HTTPError\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "AudioSegment.ffmpeg = \"C:\\\\installed\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "AudioSegment.converter = \"C:\\\\installed\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "\n",
    "TRANSCRIPTION_TYPE_LIST = [\"SPHINX\", \"GOOGLE_OLD\", \"GOOGLE_CLOUD\", \"IBM\"]\n",
    "\n",
    "\n",
    "# always use the temporary file as soon as saved to. These are global variables and global files, so be careful.\n",
    "temporary_chunk_file_name = \"temporary_chunk.flac\"\n",
    "temporary_chunk_file_name_wav = \"temporary_chunk.wav\"\n",
    "\n",
    "IBM_USERNAME = \"5dfc5316-3ce3-4eb6-990f-af095739f349\"  # form XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n",
    "IBM_PASSWORD = \"oLQpSIHfNwzp\"  # passwords are mixed-case alphanumeric strings\n",
    "\n",
    "GOOGLE_CLOUD_SPEECH_CREDENTIALS = \"\"\"{\n",
    "  \"type\": \"service_account\",\n",
    "  \"project_id\": \"fiery-aspect-162501\",\n",
    "  \"private_key_id\": \"02c3770e740ffc969962e19bdbb7bfd473a24708\",\n",
    "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQC+ac+5foaaUt35\\n3Jj6UxtfCzEBnMCz9M4mk+mL0y/wrbOynVgci8z60UG37eU/h9LIvDcXqB/YTtLN\\nzySmfG+LpCh71bHoqRY0sUmNViJ2KBQQHIZKB0esX0P6CZVel+KLEDGWNBOz8ch9\\n70SE2kng2DrppQWEWxLNbQdSOPf34baLIBVQ2AfyCiiMmsRz0Fbx4fvcMS1ynecr\\n1PhS3n6KNAVPziXS63w7jcyDSHgfiTDDLbQ2BK1f83QdEg2RsxiB8rRZLNwTR9SN\\n/+P3Y6VHPu6Yuku69bzIa7jKmlJFTaecrCqGxydD3MAt3mwyriOEn2eFjYFWYkep\\nRqGl7477AgMBAAECggEAEdnZn4o9FDqwlLwZm14vMrnZ3kzTxAsvSG6VdoZV+DpQ\\nnm4h1ItGrDzx7ExhMZOKL0d14sHgOmcpXCIPTYxc6Lp7ESD3jNhNPKNiQd3RXUJk\\nnx4NeOM11PMZbFd5qWST2HWsMGixcC06npPP2KSeSHX9D+pomf/vw1J1XT/5/0MA\\nRdzGsr8cyrHkAZpB9CFfZn5pdsnJasTyFOq4QNxNxgPBWm5cmqQdJUtSBZEgSrK5\\nRox7Myrb0X37pxFXl/8iwCNLprefQmjZQiaOcvceTwtXnSUrE78qS2XflTeO2Yb0\\nAkyvtRjUflHoQLRrF9DERV3OH2VrZn6z5kVqU0+AAQKBgQDydsDAq45pimDn5ED9\\nvUtylrgSLOnq+1CnCxMQDfVkA01qj4CpW0l9fh0kTg3kfIUl1uH5fI6EwDetDZHO\\nWcyRp2BO2oLJgNeB27pYpRYIwbJbPWfOJR+gvRqszty2CA5hmFEKhZ4wks+Z43sW\\ngQt4aE+fCvfZstqFdvm3BYD6GQKBgQDJCyl5VQujVGH5LcGgx7a+sevqInnq8V63\\nDOQGdA3Tw4D206XcF5pWWRZaK8Oqejk13rj9Z+AzcVM62aBNfvQUN6c9E9x9fMSA\\n55zaQhI5mSWhq3TQjBOGRU9BhXFw3Fa1oakKmM3luh41g9wtLyQqMDmjQxqJzxv9\\n/T7kQ1scMwKBgQDXqtWtC2wzaIjl+1vr11Ki7HlygUzYXQ7SZsFgCGp7uYxE+rwg\\n6DgoTeMyBdPJpxDwJYD/X9GNN0TOw0EsYSfbbxv1R9wJzHbk5UON0doVk+VHzwjk\\njpThbxOpHp+nsubH3KpJR6z727qZUYSM8d/4DCC2gRURKUvCZ5+bMmQVEQKBgAQc\\nUlDEyGQiiY5KvTbIXpgvkx9KbSu8m68qeE8ZeF7oFG73jOCfKuyxDZ/yXSHTNfBA\\nCZBE23Sx0H3XjUuIWP1A1g6NpWh7cJkiIzbjOvQqiXZwxwaslomcSS6Rx+wC1VMJ\\nZydsUGluEMgPViUmXZrvOX55FMXUkkHzN6H7LpW5AoGAE4UmIFgeqs+y97/yxARG\\nRVnD6DSwRH0PtZgNSX2WiYz8Z8CFGi1agteJKEZ6bmI9QsBdxJ53HH3MeAjWM7Mr\\nlb+S+ViHyFVn09lb8hTraSa3+Mlg5iKk1TMmYnKQ4G/NrRp6IbfP19LAobXgBmQv\\nBrgOpTiIHkcxTjplTdeS9kY=\\n-----END PRIVATE KEY-----\\n\",\n",
    "  \"client_email\": \"272709675122-compute@developer.gserviceaccount.com\",\n",
    "  \"client_id\": \"102127487461853832688\",\n",
    "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "  \"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\n",
    "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/272709675122-compute%40developer.gserviceaccount.com\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def extracted_from_sr_recognize_ibm(audio_data, username=IBM_USERNAME, password=IBM_PASSWORD, language=\"en-US\", show_all=False, timestamps=False,\n",
    "                                    word_confidence=False, word_alternatives_threshold=0.1):\n",
    "    assert isinstance(username, str), \"``username`` must be a string\"\n",
    "    assert isinstance(password, str), \"``password`` must be a string\"\n",
    "\n",
    "    flac_data = audio_data.get_flac_data(\n",
    "        convert_rate=None if audio_data.sample_rate >= 16000 else 16000,  # audio samples should be at least 16 kHz\n",
    "        convert_width=None if audio_data.sample_width >= 2 else 2  # audio samples should be at least 16-bit\n",
    "    )\n",
    "    url = \"https://stream-fra.watsonplatform.net/speech-to-text/api/v1/recognize?{}\".format(urlencode({\n",
    "        \"profanity_filter\": \"false\",\n",
    "        \"continuous\": \"true\",\n",
    "        \"model\": \"{}_BroadbandModel\".format(language),\n",
    "        \"timestamps\": \"{}\".format(str(timestamps).lower()),\n",
    "        \"word_confidence\": \"{}\".format(str(word_confidence).lower()),\n",
    "        \"word_alternatives_threshold\": \"{}\".format(word_alternatives_threshold)\n",
    "    }))\n",
    "    request = Request(url, data=flac_data, headers={\n",
    "        \"Content-Type\": \"audio/x-flac\",\n",
    "        \"X-Watson-Learning-Opt-Out\": \"true\",  # prevent requests from being logged, for improved privacy\n",
    "    })\n",
    "    authorization_value = base64.standard_b64encode(\"{}:{}\".format(username, password).encode(\"utf-8\")).decode(\"utf-8\")\n",
    "    request.add_header(\"Authorization\", \"Basic {}\".format(authorization_value))\n",
    "\n",
    "    try:\n",
    "        response = urlopen(request, timeout=None)\n",
    "    except HTTPError as e:\n",
    "        raise sr.RequestError(\"recognition request failed: {}\".format(e.reason))\n",
    "    except URLError as e:\n",
    "        raise sr.RequestError(\"recognition connection failed: {}\".format(e.reason))\n",
    "    response_text = response.read().decode(\"utf-8\")\n",
    "    result = json.loads(response_text)\n",
    "\n",
    "    # return results\n",
    "    if show_all: return result\n",
    "    if \"results\" not in result or len(result[\"results\"]) < 1 or \"alternatives\" not in result[\"results\"][0]:\n",
    "        raise Exception(\"Unknown Value Exception\")\n",
    "\n",
    "    transcription = []\n",
    "    for utterance in result[\"results\"]:\n",
    "        if \"alternatives\" not in utterance:\n",
    "            raise Exception(\"Unknown Value Exception. No Alternatives returned\")\n",
    "        for hypothesis in utterance[\"alternatives\"]:\n",
    "            if \"transcript\" in hypothesis:\n",
    "                transcription.append(hypothesis[\"transcript\"])\n",
    "    return \"\\n\".join(transcription)\n",
    "\n",
    "\n",
    "def get_transcription_result_by_type(audio, type, recognizer):\n",
    "    try:\n",
    "        if type == \"SPHINX\":\n",
    "            transcribed_value = recognizer.recognize_sphinx(audio)\n",
    "        elif type == \"GOOGLE_OLD\":\n",
    "            transcribed_value = recognizer.recognize_google(audio)\n",
    "        elif type == \"GOOGLE_CLOUD\":\n",
    "            transcribed_value = recognizer.recognize_google_cloud(audio,\n",
    "                                                                  credentials_json=GOOGLE_CLOUD_SPEECH_CREDENTIALS)\n",
    "        elif type == \"IBM\":\n",
    "            transcribed_value = extracted_from_sr_recognize_ibm(audio, username=IBM_USERNAME, password=IBM_PASSWORD)\n",
    "        else:\n",
    "            raise Exception(\"provided type not defined : {0}\".format(type))\n",
    "\n",
    "        return transcribed_value, True\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Could not understand audio\", False\n",
    "    except sr.RequestError as e:\n",
    "        return \"Sphinx error; {0}\".format(e), False\n",
    "    except Exception as e:\n",
    "        return \"Unknown error; {0}\".format(e), False\n",
    "\n",
    "\n",
    "def transcribe_audio_file(audio_file, ground_truth, transcription_types=TRANSCRIPTION_TYPE_LIST):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "\n",
    "    correct_classifications = 0\n",
    "    row_for_audio_instance = []\n",
    "    for type in transcription_types:\n",
    "        result, success_boolean = get_transcription_result_by_type(audio, type, recognizer)\n",
    "        if success_boolean:\n",
    "            successful_transcription = result.lower().strip() == ground_truth.lower()\n",
    "            row_for_audio_instance.extend([result, str(successful_transcription)])\n",
    "            if successful_transcription: correct_classifications += 1\n",
    "        else:\n",
    "            row_for_audio_instance.extend([result, \"Error\"])\n",
    "\n",
    "    return row_for_audio_instance, correct_classifications\n",
    "\n",
    "\n",
    "def transcribe_given_types_to_file(transcription_types=TRANSCRIPTION_TYPE_LIST):\n",
    "    header = [\"File Name\", \"Ground Truth\", \"Correct Classifications\"]\n",
    "    for type in transcription_types:\n",
    "        header.extend([type, type + \"_result_match\"])\n",
    "    rows = [header]\n",
    "\n",
    "    for sample_tuple in DATA_SAMPLES:\n",
    "        row, total_correct = transcribe_audio_file(sample_tuple[0], sample_tuple[1], transcription_types)\n",
    "        complete_row = [sample_tuple[0], sample_tuple[1], total_correct] + row\n",
    "        rows.append(complete_row)\n",
    "\n",
    "    transcription_result = open(\"transcription_result.csv\", \"w\", newline='')\n",
    "    csv_writer = csv.writer(transcription_result)\n",
    "    csv_writer.writerows(rows)\n",
    "    transcription_result.close()\n",
    "\n",
    "\n",
    "def transcribe_using_ibm():\n",
    "    file_name = \"radio.flac\"\n",
    "\n",
    "    with open(\"ibm_radio_transcribe_dump_\" + file_name.rstrip(\".flac\").rstrip(\".wav\") + \".txt\", \"w\") as d_dump:\n",
    "        file_name = \"radio_mp3_file\\\\\" + file_name\n",
    "        result = transcribe_audio_file(file_name, ground_truth=\"\", transcription_types=[\"IBM\"])\n",
    "        d_dump.write(str(result))\n",
    "\n",
    "\n",
    "def transcribe_word_ibm(file_name):\n",
    "    try:\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(file_name) as source:\n",
    "            audio = recognizer.record(source)\n",
    "\n",
    "        result_dictionary = extracted_from_sr_recognize_ibm(audio, show_all=True, word_confidence=True, timestamps=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log this.\n",
    "        print(str(e))\n",
    "    return result_dictionary\n",
    "\n",
    "\n",
    "def get_optimally_difficult_sequence(chunks, transcription_words):\n",
    "    optimal_chunks = AudioSegment.from_file(file=SILENCE_WAV, format=\"wav\")\n",
    "    silence = AudioSegment.from_file(file=SILENCE_WAV, format=\"wav\")\n",
    "\n",
    "    for chunk_index, chunk in enumerate(chunks):\n",
    "        difficulty = 0\n",
    "        while not increase_difficulty.is_difficulty_maxed(difficulty, MAX_DIFFICULTY):\n",
    "            chunk.export(temporary_chunk_file_name_wav, format=\"wav\")\n",
    "\n",
    "            (sample_rate, samples) = wv.read(temporary_chunk_file_name_wav)\n",
    "            entry, difficulty = increase_difficulty.increase(samples, difficulty)\n",
    "            wv.write(temporary_chunk_file_name_wav, sample_rate, entry)\n",
    "\n",
    "            (result, status), total_correct = transcribe_audio_file(temporary_chunk_file_name_wav,\n",
    "                                                                    transcription_words[chunk_index], [\"IBM\"])\n",
    "            if status == False or status == \"Error\" or increase_difficulty.is_difficulty_maxed(difficulty,\n",
    "                                                                                               MAX_DIFFICULTY):\n",
    "                # Technically on the error case, it should try again.\n",
    "\n",
    "                optimal_chunks = optimal_chunks + silence + \\\n",
    "                                 AudioSegment.from_file(file=temporary_chunk_file_name_wav, format=\"wav\")\n",
    "                break\n",
    "\n",
    "    return optimal_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"mockingbird_3.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "with sr.AudioFile(file_name) as source:\n",
    "    audio = recognizer.record(source)\n",
    "result_dictionary = extracted_from_sr_recognize_ibm(audio, show_all=True, word_confidence=True, timestamps=True, word_alternatives_threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_times = result_dictionary[\"results\"][0][\"alternatives\"][0]['timestamps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [], 'result_index': 0}\n",
      "{'results': [{'word_alternatives': [], 'alternatives': [{'transcript': 'a mocking ', 'confidence': 0.742, 'word_confidence': [['a', 0.551], ['mocking', 0.756]]}], 'final': True}], 'result_index': 0}\n"
     ]
    }
   ],
   "source": [
    "final_string = \"\"\n",
    "for word_entry in word_times:\n",
    "    \n",
    "    text = word_entry[0]\n",
    "    \n",
    "    if len(text) < 3:\n",
    "        continue\n",
    "        \n",
    "    start_time = float(word_entry[1])\n",
    "    end_time = float(word_entry[2])\n",
    "    \n",
    "    with sr.AudioFile(file_name) as source:\n",
    "        audio = recognizer.record(source, duration=end_time-start_time, offset=start_time)\n",
    "\n",
    "    result_dictionary = extracted_from_sr_recognize_ibm(audio, show_all=True, word_confidence=True, timestamps=False, word_alternatives_threshold=0.9)\n",
    "    print(result_dictionary)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}