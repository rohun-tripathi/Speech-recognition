{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Don't Run this generally\n",
    "\n",
    "# Decide on file. Get the samples from the present way. What do we need the samples for anyway?\n",
    "# match them with whatever way the samples were being gotten.\n",
    "\n",
    "file_name = \"data_input/hi.wav\"\n",
    "from pydub import AudioSegment\n",
    "import scipy.io.wavfile as wv\n",
    "\n",
    "audio_file = AudioSegment.from_file(file_name)\n",
    "(sample_rate, samples) = wv.read(file_name)\n",
    "\n",
    "print(samples)\n",
    "print(sample_rate)\n",
    "\n",
    "print(list(audio_file.get_array_of_samples())[1])\n",
    "import numpy as np\n",
    "shifted_samples = np.right_shift(samples, 1)\n",
    "AudioSegment.silent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Read a file.\n",
    "\n",
    "Somewhere it has a strong andd weak word sequence.\n",
    "\n",
    "send the audio start, first, second, last\n",
    "send the transcribed start, first, second and last.\n",
    "    where is is this?\n",
    "\n",
    "send the same to error system.\n",
    "\n",
    "overlay the noise on the strong word part.\n",
    "    never touch the initial file.\n",
    "    take the interesting part out, overlay, and then re-stich\n",
    "        not doing a complete overlay.\n",
    "            What all is interesting to us?\n",
    "\n",
    "see the confidence fall.\n",
    "    do it till the overall confidence falls majorly\n",
    "    save it as a beep plus error situation.\n",
    "    save the complete gradient required to get there.\n",
    "        does pydub also allow me to do noise generation?\n",
    "        \n",
    "is the overall prediction changing?\n",
    "\n",
    "NEED to read the existing to start from where the changes will begin.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"hi.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pip install pydub\n",
    "# pip install SpeechRecognition\n",
    "# pip install --upgrade watson-developer-cloud\n",
    "\n",
    "INPUT_FOLDER = 'data_input/';\n",
    "OUTPUT_FOLDER = 'data_output/';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "def saveToWav(file_name):\n",
    "    k = file_name.rfind(\".\"); # find the last occurrence of dot\n",
    "    audio = AudioSegment.from_file(INPUT_FOLDER+file_name, file_name[k+1:]);\n",
    "    audio.export(INPUT_FOLDER+file_name[:k]+'.wav', format='wav');\n",
    "    return file_name[:k]+'.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IBM Git code using python api for Watson Speech-to-text\n",
    "import json\n",
    "from os.path import join, dirname\n",
    "from watson_developer_cloud import SpeechToTextV1\n",
    "\n",
    "# Pratyush's credential\n",
    "speech_to_text = SpeechToTextV1(\n",
    "    username='13f66d27-1bb3-44a7-bbf7-014f5e60c770',\n",
    "    password='dKYgw0ZWjhae',\n",
    "    x_watson_learning_opt_out=False\n",
    ")\n",
    "\n",
    "def getTextFromSpeech(file_name):\n",
    "    with open(file_name,'rb') as audio_file:\n",
    "        return speech_to_text.recognize(audio_file, content_type='audio/wav', timestamps=True,\n",
    "            word_confidence=True, word_alternatives_threshold=0.01, continuous=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import base64\n",
    "\n",
    "try:  # attempt to use the Python 2 modules\n",
    "    from urllib import urlencode\n",
    "    from urllib2 import Request, urlopen, URLError, HTTPError\n",
    "except ImportError:  # use the Python 3 modules\n",
    "    from urllib.parse import urlencode\n",
    "    from urllib.request import Request, urlopen\n",
    "    from urllib.error import URLError, HTTPError\n",
    "    \n",
    "def extracted_from_sr_recognize_ibm(audio_file, username, password, language=\"en-US\", show_all=True, timestamps=False,\n",
    "                                    word_confidence=False, word_alternatives_threshold=0.1):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "    \n",
    "    flac_data = audio_data.get_flac_data(\n",
    "        convert_rate=None if audio_data.sample_rate >= 16000 else 16000,  # audio samples should be at least 16 kHz\n",
    "        convert_width=None if audio_data.sample_width >= 2 else 2  # audio samples should be at least 16-bit\n",
    "    )\n",
    "    url = \"https://stream.watsonplatform.net/speech-to-text/api/v1/recognize?{}\".format(urlencode({\n",
    "        \"profanity_filter\": \"false\",\n",
    "        \"continuous\": \"true\",\n",
    "        \"model\": \"{}_BroadbandModel\".format(language),\n",
    "        \"timestamps\": \"{}\".format(str(timestamps).lower()),\n",
    "        \"word_confidence\": \"{}\".format(str(word_confidence).lower()),\n",
    "        \"word_alternatives_threshold\": \"{}\".format(word_alternatives_threshold)\n",
    "    }))\n",
    "    request = Request(url, data=flac_data, headers={\n",
    "        \"Content-Type\": \"audio/x-flac\",\n",
    "        \"X-Watson-Learning-Opt-Out\": \"true\",  # prevent requests from being logged, for improved privacy\n",
    "    })\n",
    "    authorization_value = base64.standard_b64encode(\"{}:{}\".format(username, password).encode(\"utf-8\")).decode(\"utf-8\")\n",
    "    request.add_header(\"Authorization\", \"Basic {}\".format(authorization_value))\n",
    "\n",
    "    try:\n",
    "        response = urlopen(request, timeout=None)\n",
    "    except HTTPError as e:\n",
    "        raise sr.RequestError(\"recognition request failed: {}\".format(e.reason))\n",
    "    except URLError as e:\n",
    "        raise sr.RequestError(\"recognition connection failed: {}\".format(e.reason))\n",
    "    response_text = response.read().decode(\"utf-8\")\n",
    "    result = json.loads(response_text)\n",
    "\n",
    "    if show_all: return result\n",
    "    if \"results\" not in result or len(result[\"results\"]) < 1 or \"alternatives\" not in result[\"results\"][0]:\n",
    "        raise Exception(\"Unknown Value Exception\")\n",
    "\n",
    "    transcription = []\n",
    "    for utterance in result[\"results\"]:\n",
    "        if \"alternatives\" not in utterance:\n",
    "            raise Exception(\"Unknown Value Exception. No Alternatives returned\")\n",
    "        for hypothesis in utterance[\"alternatives\"]:\n",
    "            if \"transcript\" in hypothesis:\n",
    "                transcription.append(hypothesis[\"transcript\"])\n",
    "    return \"\\n\".join(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if '.wav' not in file_name:\n",
    "    file_name = saveToWav(file_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from platform import system\n",
    "\n",
    "def transcribe(file_name, only_transcription=False):\n",
    "    if system() == \"Windows\":\n",
    "        # For Rohun's Laptop\n",
    "        if only_transcription:\n",
    "            result = extracted_from_sr_recognize_ibm(open(file_name,'rb'), '13f66d27-1bb3-44a7-bbf7-014f5e60c770', 'dKYgw0ZWjhae', show_all=False)\n",
    "        else:\n",
    "            result = extracted_from_sr_recognize_ibm(open(file_name,'rb'), '13f66d27-1bb3-44a7-bbf7-014f5e60c770', 'dKYgw0ZWjhae')\n",
    "    else:\n",
    "        result = getTextFromSpeech(file_name);  \n",
    "    return result\n",
    "\n",
    "result = transcribe(INPUT_FOLDER + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dict(result):\n",
    "    result_dict = [];\n",
    "    for utterance in result[\"results\"]:\n",
    "        if \"word_alternatives\" not in utterance:\n",
    "            raise Exception(\"Unknown Value Exception. No Alternatives returned\")\n",
    "        for hypothesis in utterance[\"word_alternatives\"]:\n",
    "            result_dict.append(hypothesis)\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(json.dumps(result_dict,indent=2))\n",
    "def get_res_details(result_dict):\n",
    "    res_start_time = []; res_end_time = []; res_confidence = []; res_word = [];\n",
    "    for val in result_dict:\n",
    "        print(val['start_time'], '\\t', val['end_time'], '\\t', val['alternatives'][0]['word'], '\\t', val['alternatives'][0]['confidence'])\n",
    "        res_start_time.append(val['start_time']);\n",
    "        res_end_time.append(val['end_time']);\n",
    "        res_confidence.append(val['alternatives'][0]['confidence']);\n",
    "        res_word.append(val['alternatives'][0]['word']);\n",
    "    \n",
    "    return res_start_time, res_end_time, res_confidence, res_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise_and_export(initial_audio, first_word_audio, second_word_audio, final_audio, initial_words, first_word, second_word, final_words, first_easy):\n",
    "    # one of our major assumptions is : independently the audio will get the same transcription.\n",
    "    \n",
    "    initial_number_of_words = len(initial_words) + 1 + 1 + len(final_words)\n",
    "    noise = AudioSegment.from_file(\"silence.wav\", format=\"wav\")\n",
    "\n",
    "    if first_easy:\n",
    "        easy_word_to_modify = len(initial_words)\n",
    "    else:\n",
    "        easy_word_to_modify = len(initial_words) + 1\n",
    "    \n",
    "    if first_easy:\n",
    "        noisy_audio = initial_audio + first_word_audio.overlay(noise, times=10) + second_word_audio + final_audio\n",
    "    else:\n",
    "        noisy_audio = initial_audio + first_word_audio + second_word_audio.overlay(noise, times=10) + final_audio\n",
    "    \n",
    "    temporary_file_name = \"noisy_audio.wav\"\n",
    "    noisy_audio.export(temporary_file_name, format=\"wav\")\n",
    "    \n",
    "    result = transcribe(temporary_file_name)\n",
    "    result_dict = get_result_dict(result)\n",
    "    res_start_time, res_end_time, res_confidence, res_word = get_res_details(result_dict)\n",
    "    \n",
    "    if len(res_start_time) != initial_number_of_words:\n",
    "        # System failure. Got too tough return\n",
    "        pass\n",
    "    \n",
    "    if first_easy:\n",
    "        if first_word != res_word[easy_word_to_modify]\n",
    "            # System failure. Got too tough return\n",
    "            pass\n",
    "        retrieved_confidence = res_confidence[easy_word_to_modify]\n",
    "        print(retrieved_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 2.85 3.19 3.19 3.59\n",
      "quarter\n",
      "hour\n",
      "in\n",
      "the\n",
      "bridge\n",
      "had\n",
      "the\n",
      "prime\n",
      "minister\n",
      "crime\n",
      "one\n",
      "of\n",
      "the\n",
      "great\n",
      "2 13 14 15\n",
      "['quarter', 'hour', 'in', 'the', 'bridge', 'had', 'the', 'prime', 'minister', 'crime', 'one'] of the ['great']\n"
     ]
    }
   ],
   "source": [
    "IGNORE_START_WORDS = 7;\n",
    "HIGH_CONF_THRESHOLD = 0.9;\n",
    "LOW_CONF_THRESHOLD = 0.5;\n",
    "TIME_BEFORE_FIRST_WORD = 2;\n",
    "TIME_AFTER_SECOND_WORD = 0.5;\n",
    "BEEP = AudioSegment.from_file(INPUT_FOLDER+'beep.wav', 'wav');\n",
    "SILENCE = AudioSegment.from_file(INPUT_FOLDER+'silence.wav', 'wav');\n",
    "SILENCE = SILENCE[0:150]; # 300 ms of silence\n",
    "\n",
    "count = 1;\n",
    "i = IGNORE_START_WORDS;\n",
    "while i < len(res_end_time)-1:\n",
    "    # Check if the two consecutive words have high and low confidence and vice versa\n",
    "    if (res_confidence[i]>HIGH_CONF_THRESHOLD and res_confidence[i-1]<LOW_CONF_THRESHOLD) or (res_confidence[i-1]>HIGH_CONF_THRESHOLD and res_confidence[i]<LOW_CONF_THRESHOLD):\n",
    "        initial = i\n",
    "        first_easy = res_confidence[i-1]>res_confidence[i]\n",
    "        print('--', res_start_time[i-1], res_end_time[i-1], res_start_time[i], res_end_time[i])\n",
    "        \n",
    "        transcription_start_index = -1\n",
    "        transcription_end_index = -1\n",
    "        \n",
    "        # Get the start and end time of the 5 seconds sample\n",
    "        audio_start_time = res_start_time[i-1] - TIME_BEFORE_FIRST_WORD;\n",
    "        if audio_start_time<0:\n",
    "            audio_start_time = 0;\n",
    "            transcription_start_index = 0\n",
    "            \n",
    "        audio_end_time = res_end_time[i] + TIME_AFTER_SECOND_WORD;\n",
    "        if audio_end_time>res_end_time[len(res_end_time)-1]:\n",
    "            audio_end_time = res_end_time[len(res_end_time)-1];\n",
    "            transcription_end_index = len(res_end_time) - 1\n",
    "        \n",
    "        # Make sure that the start and end time is not between a word\n",
    "        for j in range(0,len(res_end_time)-1):\n",
    "            if res_start_time[j+1]>audio_start_time:\n",
    "                audio_start_time = res_start_time[j];\n",
    "                transcription_start_index = j\n",
    "                break;\n",
    "        for j in range(0,len(res_end_time)):\n",
    "            if res_end_time[j]>audio_end_time:\n",
    "                audio_end_time = res_end_time[j];\n",
    "                transcription_end_index = j\n",
    "                \n",
    "                # Don't understand this below. Will like to ask about it.\n",
    "                i = j-1; # If i put i = j, then there won't be any overlap\n",
    "                \n",
    "                break;\n",
    "        #print(audio_start_time, audio_end_time)\n",
    "        for counter in range(transcription_start_index, transcription_end_index + 1):\n",
    "            print(res_word[counter])\n",
    "        # Make an audio file with these time and store it as wav\n",
    "        k = file_name.rfind(\".\"); # find the last occurrence of dot\n",
    "        audio = AudioSegment.from_file(INPUT_FOLDER+file_name, file_name[k+1:]);\n",
    "        audio = audio[audio_start_time*1000:audio_end_time*1000];\n",
    "            \n",
    "        # audio.export(OUTPUT_FOLDER+file_name[:k]+'_'+str(count)+'_NO_B.wav', format='wav');\n",
    "\n",
    "        # Make an audio file with beep and store it as wav\n",
    "        audio = AudioSegment.from_file(INPUT_FOLDER+file_name, file_name[k+1:]);\n",
    "        \n",
    "        initial_audio = audio[audio_start_time*1000:res_end_time[i-2]*1000]\n",
    "        first_word_audio = audio[res_end_time[i-2]*1000:res_start_time[i]*1000]\n",
    "        second_word_audio = audio[res_end_time[i]*1000:res_start_time[i+1] * 1000]\n",
    "        final_audio = audio[res_start_time[i+1]*1000:audio_end_time*1000]\n",
    "        \n",
    "        initial_words = res_word[transcription_start_index:i-1]\n",
    "        first_word = res_word[i-1]\n",
    "        second_word = res_word[i]\n",
    "        final_words = res_word[i+1:transcription_end_index+1]\n",
    "        \n",
    "        print(transcription_start_index, i-1, i, transcription_end_index)\n",
    "        print(initial_words, first_word, second_word, final_words)\n",
    "        \n",
    "        add_noise_and_export(initial_audio, first_word_audio, second_word_audio, final_audio, initial_words, first_word, second_word, final_words, first_easy)\n",
    "        \n",
    "        audio = audio[audio_start_time*1000:res_end_time[i-2]*1000] + \\\n",
    "        SILENCE + BEEP + SILENCE + \\\n",
    "        audio[res_end_time[i-2]*1000:res_start_time[i+1]*1000] + \\\n",
    "        SILENCE + BEEP + SILENCE + \\\n",
    "        audio[res_start_time[i+1]*1000:audio_end_time*1000]\n",
    "        \n",
    "        #audio.export(OUTPUT_FOLDER+file_name[:k]+'_'+str(count)+'_B.wav', format='wav');\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Just store the two words\n",
    "        audio = AudioSegment.from_file(INPUT_FOLDER+file_name, file_name[k+1:]);\n",
    "        audio = audio[res_end_time[i-2]*1000:res_start_time[i+1]*1000];\n",
    "        audio.export(OUTPUT_FOLDER+file_name[:k]+'_'+str(count)+'_TWO.wav', format='wav');\n",
    "\n",
    "        count = count+1;        \n",
    "    i = i+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob, os, csv\n",
    "\n",
    "NUMBER_TO_TRANSCRIBE = 1\n",
    "\n",
    "files_to_transcribe = glob.glob(os.path.join(OUTPUT_FOLDER, \"*_NO_B.wav\"))\n",
    "\n",
    "with open(\"transcription_output.csv\", \"w\") as trasncription_output:\n",
    "    rows = [[\"File Name\", \"IBM stt perdiction\", \"correct (manually checked)\", \"manual attempt\", \"comprehensible (manually checked)\"]]\n",
    "    for index, file_name_path in enumerate(files_to_transcribe):\n",
    "        if index >= NUMBER_TO_TRANSCRIBE:\n",
    "            break\n",
    "        transcription = transcribe(file_name_path, True).replace(\"\\n\", \" \").replace(\"  \", \" \")\n",
    "        rows.append([file_name_path, transcription, \"\", transcription, \"\"])\n",
    "    writer = csv.writer(trasncription_output)\n",
    "    writer.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}