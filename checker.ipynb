{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# AudioSegment.ffmpeg = \"C:\\\\installed\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "# AudioSegment.converter = \"C:\\\\installed\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "\n",
    "from watson_developer_cloud import TextToSpeechV1\n",
    "\n",
    "import glob\n",
    "import json\n",
    "from random import shuffle\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "\n",
    "import global_constants\n",
    "\n",
    "import re\n",
    "\n",
    "import function_library\n",
    "\n",
    "# Rohun's IBM credential\n",
    "tts = TextToSpeechV1(\n",
    "    username=global_constants.IBM_USERNAME,\n",
    "    password=global_constants.IBM_PASSWORD,\n",
    ")\n",
    "\n",
    "def synthesize_number(number):\n",
    "    try:\n",
    "        byte_audio = tts.synthesize(str(number), accept='audio/wav', voice=\"en-US_AllisonVoice\")\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            byte_audio = tts.synthesize(str(number), accept='audio/wav', voice=\"en-US_AllisonVoice\")\n",
    "        except Exception as e:\n",
    "            return AudioSegment.silent(duration=250)\n",
    "\n",
    "    # The sample_width, frame_rate and the channels are empirical values. No values in documentation.\n",
    "    sound = AudioSegment(\n",
    "        data=byte_audio,\n",
    "\n",
    "        sample_width=2,\n",
    "        frame_rate=22050,\n",
    "        channels=1\n",
    "    )\n",
    "\n",
    "    return sound\n",
    "\n",
    "\n",
    "def stich_audio_files(file_list, silence, post_number_silence, location, tag_extension):\n",
    "    stiched_result = AudioSegment.empty()\n",
    "\n",
    "    USER_STUDY_OUTPUT_DATA = \"user_study_output\\\\\"\n",
    "    for index, audio_file in enumerate(file_list):\n",
    "        try:\n",
    "            audio = AudioSegment.from_file(USER_STUDY_OUTPUT_DATA + location + audio_file + tag_extension, format=\"wav\")\n",
    "            number = synthesize_number(index + 1)\n",
    "            stiched_result += silence + number + post_number_silence + audio\n",
    "        except Exception as e:\n",
    "            logging.error(str(e))\n",
    "\n",
    "    return stiched_result\n",
    "\n",
    "\n",
    "\n",
    "def crop_and_save_to_wav(file_name):\n",
    "    just_name = file_name.rfind(\".\")\n",
    "    audio = AudioSegment.from_file(file_name, format=\"mp3\")[3000:6000]\n",
    "    \n",
    "    for value in [0, 10, 20, 30, 40]:\n",
    "        reduced_audio = audio - value\n",
    "        reduced_audio.export(file_name[:just_name] + \"_\" + str(value) + \".wav\", format=\"wav\")\n",
    "\n",
    "        \n",
    "def decrease_beep_strength():\n",
    "    beep = AudioSegment.from_file(\"data_input\\\\\" + 'beep.wav', 'wav')\n",
    "    for i in range(5):\n",
    "        beep = beep - 10\n",
    "        beep.export(out_f=\"data_input\\\\beep_\" + str(i) + \".wav\", format=\"wav\")\n",
    "        \n",
    "\n",
    "    \n",
    "'Reads files with the specified Noise types in allowed values'\n",
    "\n",
    "def read_files(file_list, allowed_values, columns):\n",
    "    result_dataframe = pd.DataFrame()\n",
    "    \n",
    "    for file_name in file_list:\n",
    "        data_frame = pd.read_csv(file_name, names=columns, usecols=range(len(columns)))\n",
    "        if len(data_frame) == 0:\n",
    "            continue\n",
    "        \n",
    "        result_dataframe = result_dataframe.append(data_frame, ignore_index=True)\n",
    "    \n",
    "    result_dataframe = result_dataframe[result_dataframe[\"noise_type\"].isin(allowed_values)]\n",
    "    \n",
    "    result_dataframe = result_dataframe[result_dataframe[\"noise\"] != -1]\n",
    "    \n",
    "    return result_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Parameters that are being used in this exercise'''\n",
    "\n",
    "# Data Set Iteration number\n",
    "data_version = \"4\"\n",
    "\n",
    "# Captcha Version. Options - 2, 3a, 3b, 4\n",
    "captcha_type = \"4\"\n",
    "\n",
    "if captcha_type != \"3b\":\n",
    "    filter_keyword_list = [\"REFACTORED_White_YT_VERSION_\" + captcha_type, \"REFACTORED_White_PODCAST_VERSION_\" + captcha_type, \"REFACTORED_PODCAST_VERSION_\" + captcha_type]\n",
    "else:\n",
    "    filter_keyword_list = [\"REFACTORED_White_YT_VERSION_\" + captcha_type, \"REFACTORED_White_PODCAST_VERSION_\" + captcha_type, \"REFACTORED_PODCAST_VERSION_\" + captcha_type, \"REFACTORED_REDONE_PODCAST_VERSION_\" + captcha_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add tag and time to name and use json to dump file names. json file uses same name.\n",
    "\n",
    "complete_file_list = []\n",
    "for filter_keyword in filter_keyword_list:\n",
    "    complete_file_list.extend(glob.glob(\"logs/*selected*\" + filter_keyword + \".csv\"))\n",
    "\n",
    "if captcha_type == \"4\":\n",
    "    column_word = [\"name\", \"version\", \"original_text\", \"noise\", \"complete\", \"source_type\", \"noise_type\", \"transcript\", \"reduced_word\"]\n",
    "else:\n",
    "    column_word = [\"name\", \"version\", \"start\", \"end\", \"original_text\", \"noise\", \"first_word_easy\", \"first_confidence\", \"second_confidence\", \"source_type\", \"noise_type\", \"first_word\", \"second_word\"]\n",
    "\n",
    "file_dataframe= read_files(complete_file_list, [\"White\"], column_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_ten(file_dataframe, source, data_version, captcha_type):\n",
    "    'Copies the N files selected and stored in the log file from the specified source location to \"vX\" destination folder'\n",
    "    \n",
    "    NUMBER_TO_SELECT = 1000\n",
    "    \n",
    "    destination = \"Test_data\\\\v\" + data_version + \"\\\\c\" + captcha_type + \"_\" + str(datetime.now().timestamp()).replace(\".\",\"\")\n",
    "    os.makedirs(destination, exist_ok = True)\n",
    "\n",
    "    dictionary_gt = []\n",
    "    audio_name_list = []\n",
    "    rows = [[\"Name\", \"Captcha\", \"Word_Detected\", \"Text_Detected\"]]\n",
    "   \n",
    "    for index, row in file_dataframe.head(NUMBER_TO_SELECT).iterrows():\n",
    "        audio_file = row[\"name\"]    \n",
    "        \n",
    "        if captcha_type == \"4\":\n",
    "            transcript = row[\"reduced_word\"]\n",
    "        else: \n",
    "            if row[\"first_word_easy\"]:\n",
    "                transcript = row[\"first_word\"]\n",
    "            else:\n",
    "                transcript = row[\"second_word\"]\n",
    "        \n",
    "        dictionary_gt.append({\"audio\" : audio_file + \".wav\", \"gt\" : transcript})\n",
    "        audio_name_list.append({\"audio\" : audio_file + \".wav\"})\n",
    "        rows.append([audio_file, captcha_type])\n",
    "        \n",
    "        audio = AudioSegment.from_file(source + audio_file + \".wav\", format=\"wav\")\n",
    "        output_path = os.path.join(destination, audio_file + \".wav\")\n",
    "        audio.export(output_path, format=\"wav\")\n",
    "        \n",
    "    gt_folder = \"Test_data\\\\v\" + data_version + \"\\\\gt_data\"\n",
    "    os.makedirs(gt_folder, exist_ok = True)\n",
    "    json.dump(dictionary_gt, open(os.path.join(gt_folder, \"gt\" + captcha_type + \".json\"), \"w\"))\n",
    "    \n",
    "    audio_folder = \"Test_data\\\\v\" + data_version + \"\\\\audioname\"\n",
    "    os.makedirs(audio_folder, exist_ok = True)\n",
    "    json.dump(audio_name_list, open(os.path.join(audio_folder, \"aname\" + captcha_type + \".json\"), \"w\"))\n",
    "    \n",
    "    selection_folder = \"Test_data\\\\v\" + data_version + \"\\\\selection\"\n",
    "    os.makedirs(selection_folder, exist_ok = True)\n",
    "    with open(os.path.join(selection_folder, \"sample\" + captcha_type + \".csv\"), \"w\", newline=\"\") as sample_file:\n",
    "        csv.writer(sample_file).writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(file_dataframe))\n",
    "\n",
    "# chunk_source = \"/home/riot/Desktop/AudioCaptcha/audio_data/data_chunk_stage/podcast_lecture\"\n",
    "chunk_source = \"/home/riot/Desktop/AudioCaptcha/audio_data/data_chunk_stage/lecture\"\n",
    "\n",
    "\n",
    "# create_ten(file_dataframe, \"C:\\\\Users\\\\IBM_ADMIN\\\\speech_recognition\\\\data_output_selected\\\\\", data_version, captcha_type)\n",
    "\n",
    "def extract_file_list():\n",
    "    '''Select the entries that pass manual filtering'''\n",
    "    \n",
    "    if captcha_type == \"2\":\n",
    "        file_name = \"/home/riot/Desktop/AudioCaptcha/speech-recognition/Test_Data/v3_3/audioname/aname2.json\"\n",
    "        audio_dict = json.load(open(file_name, \"r\"))\n",
    "        return [entry[\"audio\"] for entry in audio_dict]\n",
    "\n",
    "    elif captcha_type == \"3b\":\n",
    "        \n",
    "        # For 3b the data was combined from two iterations of data production.\n",
    "        \n",
    "        file_name = \"/home/riot/Desktop/AudioCaptcha/speech-recognition/Test_Data/v3_3/audioname/aname3b.json\"\n",
    "        audio_dict = json.load(open(file_name, \"r\"))\n",
    "        return [entry[\"audio\"] for entry in audio_dict]\n",
    "    \n",
    "    elif captcha_type == \"4\":\n",
    "        file_name = \"/home/riot/Desktop/AudioCaptcha/speech-recognition/Test_Data/v3_3/audioname/aname4.json\"\n",
    "        audio_dict = json.load(open(file_name, \"r\"))\n",
    "        return [entry[\"audio\"] for entry in audio_dict]\n",
    "    else:\n",
    "        raise Exception(\"Unsupported\")\n",
    "\n",
    "    \n",
    "\n",
    "def add_noise_and_export(output_directory, noise_to_add, processed_type, audio):\n",
    "    '''Overlay noise. Export to output folder.'''\n",
    "    silence = AudioSegment.silent(duration=250)\n",
    "        \n",
    "    type_2 = silence + audio + silence\n",
    "    type_2 = type_2.overlay(noise_to_add, loop=True)\n",
    "\n",
    "    output = os.path.join(output_directory, os.path.join(\"from_c\" + captcha_type, os.path.join(\"c\" + processed_type, \"file_\" + str(index) + file_format)))\n",
    "    type_2.export(output, format=\"wav\")\n",
    "    \n",
    "# set output directories.    \n",
    "output_directory = \"/home/riot/Desktop/AudioCaptcha/speech-recognition/Test_Data/v4\"\n",
    "audio_list = extract_file_list()\n",
    "print(len(audio_list))\n",
    "\n",
    "file_format = \".wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American_Civil_War_chunk_54_1497156637776667_count_0_noise_28_noise_type_White.wav\n",
      "American_revolution_lecture_chunk_107_1497534345207332_count_2_noise_23_noise_type_White.wav\n",
      "American_revolution_lecture_chunk_47_1497156637776667_count_3_noise_15_noise_type_White.wav\n",
      "FinneginsWake_chunk_129_1499080254532628_count_0_noise_7_noise_type_White.wav\n",
      "Google_IO_2017_chunk_196_1497534345207332_count_1_noise_19_noise_type_White.wav\n",
      "Google_IO_2017_chunk_32_1497156637776667_count_0_noise_23_noise_type_White.wav\n",
      "Google_IO_2017_chunk_96_1497156637776667_count_0_noise_18_noise_type_White.wav\n",
      "History_4A_Fall_2007_UC_Berkeley_Lecture_24_Monarchy_at_Rome_The_Age_of_Augustus_20476_chunk_111_1499080254532628_count_0_noise_0_noise_type_White.wav\n",
      "History_4A_Fall_2007_UC_Berkeley_Lecture_24_Monarchy_at_Rome_The_Age_of_Augustus_20476_chunk_129_1499080254532628_count_0_noise_0_noise_type_White.wav\n",
      "Mcluhan-Mckenna_1_chunk_27_1499080254532628_count_1_noise_26_noise_type_White.wav\n",
      "Nikola_Tesla_chunk_15_1497534345207332_count_0_noise_22_noise_type_White.wav\n",
      "Nikola_Tesla_chunk_30_1497156637776667_count_1_noise_7_noise_type_White.wav\n",
      "Shakespeare_chunk_38_1497156637776667_count_0_noise_23_noise_type_White.wav\n",
      "Shakespeare_chunk_60_1497156637776667_count_0_noise_10_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations02-16_chunk_58_1499080254532628_count_0_noise_14_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations04-16_chunk_57_1499080254532628_count_0_noise_25_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations06-16_chunk_63_1499080254532628_count_0_noise_21_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations06-16_chunk_97_1499080254532628_count_0_noise_13_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations08-16_chunk_21_1499080254532628_count_0_noise_0_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations08-16_chunk_3_1499080254532628_count_1_noise_17_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations08-16_chunk_41_1499080254532628_count_0_noise_9_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations08-16_chunk_82_1499080254532628_count_0_noise_6_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations08-16_chunk_82_1499080254532628_count_1_noise_26_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations09-16_chunk_63_1499080254532628_count_0_noise_11_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations09-16_chunk_64_1499080254532628_count_0_noise_7_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations10-16_chunk_14_1499080254532628_count_0_noise_13_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations10-16_chunk_14_1499080254532628_count_1_noise_19_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations12-16_chunk_63_1499080254532628_count_0_noise_29_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations12-16_chunk_64_1499080254532628_count_0_noise_18_noise_type_White.wav\n",
      "TerenceMckenna-TrueHallucinations15-16_chunk_46_1499080254532628_count_0_noise_31_noise_type_White.wav\n",
      "TheVoynichManuscript_chunk_117_1499080254532628_count_1_noise_0_noise_type_White.wav\n",
      "Western_Philosophy_chunk_58_1497534345207332_count_0_noise_15_noise_type_White.wav\n",
      "Yoshua_Bengio_chunk_59_1497156637776667_count_1_noise_0_noise_type_White.wav\n"
     ]
    }
   ],
   "source": [
    "audio_entries_not_found = []\n",
    "\n",
    "gt_rows = []\n",
    "if captcha_type == \"3b\":\n",
    "\n",
    "    # for each audio item, get row.\n",
    "    regex = \".*_chunk_\\\\d*\"\n",
    "\n",
    "    noise = AudioSegment.from_file(os.path.join(\"parameter_input\", \"noise.wav\"), format=\"wav\")\n",
    "        \n",
    "    for index, audio_entry in enumerate(sorted(audio_list)):\n",
    "\n",
    "        audio_name = audio_entry.rstrip(file_format)\n",
    "        row = file_dataframe[file_dataframe.name == audio_name]\n",
    "        \n",
    "        print(audio_entry)\n",
    "\n",
    "        name = re.match(regex, audio_name).group(0)\n",
    "\n",
    "        start = row.start.iloc[0]\n",
    "        end = row.end.iloc[0]\n",
    "        noise_for_row = noise + row.noise.iloc[0]\n",
    "        \n",
    "        if row.first_word_easy.iloc[0]:\n",
    "            gt = row.first_word.iloc[0]\n",
    "            weak_word = [row.second_word.iloc[0]]\n",
    "        else:\n",
    "            gt = row.second_word.iloc[0]\n",
    "            weak_word = [row.first_word.iloc[0]]\n",
    "\n",
    "        gt_rows.append([index, audio_entry, gt, str(weak_word)])\n",
    "        \n",
    "        try:\n",
    "            original_audio = AudioSegment.from_file(os.path.join(chunk_source, name + file_format), \"wav\")\n",
    "            audio = original_audio[start * 1000:end * 1000]\n",
    "            \n",
    "            audio.export(\"archive/tmp/abcd_efgh.wav\", \"wav\")\n",
    "            \n",
    "            result = function_library.transcribe_robustly(\"archive/tmp/abcd_efgh.wav\")\n",
    "            result_dictionary = function_library.get_dict(result)\n",
    "            word_object_list = function_library.get_word_list(result_dictionary)\n",
    "\n",
    "            last_two_word_start = None\n",
    "            \n",
    "            print(\"\\ntarget word : \" + row.first_word.iloc[0])\n",
    "            for word_object in reversed(word_object_list):\n",
    "                print(word_object.word)\n",
    "                if word_object.word == row.first_word.iloc[0]:\n",
    "                    last_two_word_start = word_object.start_time\n",
    "                    print(\"Word Found\")\n",
    "                    break\n",
    "            \n",
    "            print(last_two_word_start)\n",
    "            \n",
    "            if last_two_word_start is None:\n",
    "                if len(word_object_list) > 1:\n",
    "                    print(word_object_list[-1].start_time)\n",
    "                    print(word_object_list[-2].start_time)\n",
    "                    last_two_word_start = word_object_list[-2].start_time\n",
    "                else:\n",
    "                    last_two_word_start = max(0, end - 1)\n",
    " \n",
    "        except FileNotFoundError as fE:\n",
    "            audio_entries_not_found.append(name + file_format)\n",
    "            continue\n",
    "\n",
    "        print(audio_entry)\n",
    "\n",
    "        # captcha type 2\n",
    "        audio = original_audio[(start + last_two_word_start) * 1000:end * 1000]\n",
    "        add_noise_and_export(output_directory, noise_for_row, '2', audio)\n",
    "\n",
    "        # captcha type 3\n",
    "        audio = original_audio[start * 1000:end * 1000]\n",
    "        add_noise_and_export(output_directory, noise_for_row, '3', audio)\n",
    "\n",
    "        # captcha type 4\n",
    "        min_end = min(25, end + 3)\n",
    "        audio = original_audio[start * 1000:min_end * 1000]\n",
    "        add_noise_and_export(output_directory, noise_for_row, \"4\", audio)\n",
    "        \n",
    "elif captcha_type == \"4\":\n",
    "    # for each audio item, get row.\n",
    "    clip_source = \"/home/riot/Desktop/AudioCaptcha/speech-recognition/Test_Data/v3_USED/c4_1499150924805736\"\n",
    "\n",
    "    for index, audio_entry in enumerate(sorted(audio_list)):\n",
    "        \n",
    "        audio_name = audio_entry.rstrip(file_format)\n",
    "        row = file_dataframe[file_dataframe.name == audio_name]\n",
    "\n",
    "        gt_rows.append([index, audio_entry, row.reduced_word.iloc[0]])\n",
    "        \n",
    "        try:\n",
    "            original_audio = AudioSegment.from_file(os.path.join(clip_source, audio_entry), \"wav\")\n",
    "        except FileNotFoundError as fE:\n",
    "            audio_entries_not_found.append(audio_entry)\n",
    "            continue\n",
    "\n",
    "        print(audio_entry)\n",
    "\n",
    "        # captcha type 4\n",
    "        output = os.path.join(output_directory, os.path.join(\"from_c\" + captcha_type, os.path.join(\"c4\", \"file_\" + str(index) + file_format)))\n",
    "        original_audio.export(output, format=\"wav\")\n",
    "\n",
    "elif captcha_type == \"2\":\n",
    "\n",
    "    # for each audio item, get row.\n",
    "\n",
    "    file_format = \".wav\"\n",
    "    regex = \".*_chunk_\\\\d*\"\n",
    "\n",
    "    noise = AudioSegment.from_file(os.path.join(\"parameter_input\", \"noise.wav\"), format=\"wav\")\n",
    "\n",
    "    for index, audio_entry in enumerate(sorted(audio_list)):\n",
    "\n",
    "        audio_name = audio_entry.rstrip(file_format)\n",
    "        row = file_dataframe[file_dataframe.name == audio_name]\n",
    "\n",
    "        name = re.match(regex, audio_name).group(0)\n",
    "\n",
    "        start = row.start.iloc[0]\n",
    "        end = row.end.iloc[0]\n",
    "        noise_for_row = noise + row.noise.iloc[0]\n",
    "        \n",
    "        if row.first_word_easy.iloc[0]:\n",
    "            gt = row.first_word.iloc[0]\n",
    "            weak_word = [row.second_word.iloc[0]]\n",
    "        else:\n",
    "            gt = row.second_word.iloc[0]\n",
    "            weak_word = [row.first_word.iloc[0]]\n",
    "\n",
    "        gt_rows.append([index, audio_entry, gt, str(weak_word)])\n",
    "\n",
    "        try:\n",
    "            original_audio = AudioSegment.from_file(os.path.join(chunk_source, name + file_format), \"wav\")\n",
    "        except FileNotFoundError as fE:\n",
    "            audio_entries_not_found.append(name + file_format)\n",
    "            continue\n",
    "\n",
    "        print(audio_entry)\n",
    "\n",
    "        # captcha type 2\n",
    "        audio = original_audio[start * 1000:end * 1000]\n",
    "        add_noise_and_export(output_directory, noise_for_row, '2', audio)\n",
    "\n",
    "        # captcha type 3\n",
    "        max_start = max(start - 3, 0)\n",
    "        audio = original_audio[max_start * 1000:end * 1000]\n",
    "        add_noise_and_export(output_directory, noise_for_row, '3', audio)\n",
    "\n",
    "        # captcha type 4\n",
    "        min_end = min(25, end + 3)\n",
    "        audio = original_audio[max_start * 1000:min_end * 1000]\n",
    "        add_noise_and_export(output_directory, noise_for_row, \"4\", audio)\n",
    "\n",
    "gt_file = os.path.join(output_directory, os.path.join(\"from_c\" + captcha_type, \"gt.csv\"))\n",
    "with open(gt_file, \"w\", newline=\"\") as fp: \n",
    "    csv.writer(fp).writerows(gt_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['American_Civil_War_chunk_54_1497156637776667_count_0_noise_28_noise_type_White.wav',\n",
       " 'American_revolution_lecture_chunk_107_1497534345207332_count_2_noise_23_noise_type_White.wav',\n",
       " 'American_revolution_lecture_chunk_47_1497156637776667_count_3_noise_15_noise_type_White.wav',\n",
       " 'FinneginsWake_chunk_129_1499080254532628_count_0_noise_7_noise_type_White.wav',\n",
       " 'Google_IO_2017_chunk_196_1497534345207332_count_1_noise_19_noise_type_White.wav',\n",
       " 'Google_IO_2017_chunk_32_1497156637776667_count_0_noise_23_noise_type_White.wav',\n",
       " 'Google_IO_2017_chunk_96_1497156637776667_count_0_noise_18_noise_type_White.wav',\n",
       " 'History_4A_Fall_2007_UC_Berkeley_Lecture_24_Monarchy_at_Rome_The_Age_of_Augustus_20476_chunk_111_1499080254532628_count_0_noise_0_noise_type_White.wav',\n",
       " 'History_4A_Fall_2007_UC_Berkeley_Lecture_24_Monarchy_at_Rome_The_Age_of_Augustus_20476_chunk_129_1499080254532628_count_0_noise_0_noise_type_White.wav',\n",
       " 'Mcluhan-Mckenna_1_chunk_27_1499080254532628_count_1_noise_26_noise_type_White.wav',\n",
       " 'Nikola_Tesla_chunk_15_1497534345207332_count_0_noise_22_noise_type_White.wav',\n",
       " 'Nikola_Tesla_chunk_30_1497156637776667_count_1_noise_7_noise_type_White.wav',\n",
       " 'Shakespeare_chunk_38_1497156637776667_count_0_noise_23_noise_type_White.wav',\n",
       " 'Shakespeare_chunk_60_1497156637776667_count_0_noise_10_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations02-16_chunk_58_1499080254532628_count_0_noise_14_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations04-16_chunk_57_1499080254532628_count_0_noise_25_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations06-16_chunk_63_1499080254532628_count_0_noise_21_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations06-16_chunk_97_1499080254532628_count_0_noise_13_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations08-16_chunk_21_1499080254532628_count_0_noise_0_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations08-16_chunk_3_1499080254532628_count_1_noise_17_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations08-16_chunk_41_1499080254532628_count_0_noise_9_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations08-16_chunk_82_1499080254532628_count_0_noise_6_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations08-16_chunk_82_1499080254532628_count_1_noise_26_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations09-16_chunk_63_1499080254532628_count_0_noise_11_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations09-16_chunk_64_1499080254532628_count_0_noise_7_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations10-16_chunk_14_1499080254532628_count_0_noise_13_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations10-16_chunk_14_1499080254532628_count_1_noise_19_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations12-16_chunk_63_1499080254532628_count_0_noise_29_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations12-16_chunk_64_1499080254532628_count_0_noise_18_noise_type_White.wav',\n",
       " 'TerenceMckenna-TrueHallucinations15-16_chunk_46_1499080254532628_count_0_noise_31_noise_type_White.wav',\n",
       " 'TheVoynichManuscript_chunk_117_1499080254532628_count_1_noise_0_noise_type_White.wav',\n",
       " 'Western_Philosophy_chunk_58_1497534345207332_count_0_noise_15_noise_type_White.wav',\n",
       " 'Yoshua_Bengio_chunk_59_1497156637776667_count_1_noise_0_noise_type_White.wav']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_file_list = glob.glob(\"user_study_output\\\\user_study_initial_output\\\\*.wav\")\n",
    "shuffle(complete_file_list)\n",
    "\n",
    "dbfs_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:09:58) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for file_entry in complete_file_list:\n",
    "    audio = AudioSegment.from_file(file_entry, format=\"wav\")\n",
    "    dbfs_list.append(audio.dBFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.930842618\n",
      "4.49456667099\n",
      "-11.436275947\n",
      "169\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(dbfs_list)\n",
    "std = np.std(dbfs_list)\n",
    "\n",
    "print(mean)\n",
    "print(std)\n",
    "\n",
    "number = 0\n",
    "for dbfs_value in dbfs_list:\n",
    "    number += 1 if dbfs_value > (mean + std) else 0\n",
    "#     if dbfs_value > (mean + std):\n",
    "#         print(dbfs_value)\n",
    "print((mean + std))\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'uses selected_file_data for creating a stiched audio file'\n",
    "\n",
    "def create_stiched_output(selected_file_data, output_tag):  \n",
    "    output_file_prefix = \"stiched_output\\\\study\" + output_tag\n",
    "\n",
    "    json.dump(selected_file_data, open(output_file_prefix + \".json\", \"w\"))\n",
    "\n",
    "    silence = AudioSegment.silent(duration=1000)\n",
    "    post_number_silence = AudioSegment.silent(duration=500)\n",
    "\n",
    "    source_location = \"reduced_confidence\\\\\"\n",
    "\n",
    "    for tagged_format in [\"_W_B.wav\", \"_O_B.wav\", \".wav\"]:\n",
    "\n",
    "        f = stich_audio_files(selected_file_data, silence, post_number_silence, source_location, tagged_format)\n",
    "\n",
    "        f.export(out_f=\"stiched_output\\\\study\" + output_tag + tagged_format, format=\"wav\")\n",
    "\n",
    "        print(\"Done for {}\", tagged_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bin the video accordoing to the initial confidence of the strong word.\n",
    "\n",
    "def add_to_appropriate_df(original, variable_set):\n",
    "    for df_dict in variable_set:\n",
    "\n",
    "        first_criteria = (original.first_word_easy == True) & (original.first_confidence > df_dict[\"low\"]) & (original.first_confidence <= df_dict[\"high\"])\n",
    "        second_criteria = (original.first_word_easy == False) & (original.second_confidence > df_dict[\"low\"]) & (original.second_confidence <= df_dict[\"high\"])\n",
    "        \n",
    "        df_dict[\"df\"] = df_dict[\"df\"].append(original[first_criteria])\n",
    "        df_dict[\"df\"] = df_dict[\"df\"].append(original[second_criteria])\n",
    "    \n",
    "    return variable_set\n",
    "\n",
    "\n",
    "variable_set = []\n",
    "\n",
    "step = 5\n",
    "for counter in range(70, 100, step):\n",
    "    variable_set.append({\"low\" : float(counter)/100, \"high\" : float(counter + step)/100, \"df\" : pd.DataFrame()})\n",
    "    \n",
    "variable_set = add_to_appropriate_df(file_dataframe, variable_set)\n",
    "\n",
    "output_tag = \"_Two_Words_\" + str(datetime.now().timestamp()).replace(\".\",\"\")\n",
    "\n",
    "def create_audio_by_confidence():\n",
    "\n",
    "    for df_dict in variable_set:\n",
    "        df = df_dict[\"df\"]\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "\n",
    "        extended_tag = output_tag + \"_Low_\" + str(df_dict[\"low\"]) + \"_High_\" + str(df_dict[\"high\"])\n",
    "        selected_file_list = list(df.name)[:Number_of_entries]\n",
    "\n",
    "        create_stiched_output(selected_file_list, extended_tag)\n",
    "\n",
    "        print(\"Done for : \", extended_tag)\n",
    "\n",
    "def create_for_complete_list():\n",
    "    # shuffle(complete_file_data)\n",
    "    create_stiched_output(list(file_dataframe.name), output_tag)\n",
    "    \n",
    "create_for_complete_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stich_audio_alternate_files():\n",
    "    \"\"\"Stiches 5 second random char Google CAPTCHAs to create 10 second CAPTCHAs\"\"\"\n",
    "    \n",
    "    items = json.loads('''[ {\"audio\":\"output_149449394454942.wav\", \"gt\":\"89016\"},\n",
    "  {\"audio\":\"output_149449657320933.wav\", \"gt\":\"43417\"},\n",
    "  {\"audio\":\"output_1494487771961015.wav\", \"gt\":\"81330\"},\n",
    "  {\"audio\":\"output_1494493574786677.wav\", \"gt\":\"62384\"},\n",
    "  {\"audio\":\"output_1494496272313691.wav\", \"gt\":\"73592\"},\n",
    "  {\"audio\":\"output_1494496294872982.wav\", \"gt\":\"10105\"},\n",
    "  {\"audio\":\"output_1494496519281245.wav\", \"gt\":\"38695\"},\n",
    "  {\"audio\":\"output_1494496601054923.wav\", \"gt\":\"80168\"},\n",
    "  {\"audio\":\"output_1494496664266538.wav\", \"gt\":\"85780\"},\n",
    "  {\"audio\":\"output_1494497754558948.wav\", \"gt\":\"99358\"},\n",
    "  {\"audio\":\"output_1494497804519805.wav\", \"gt\":\"08884\"},\n",
    "  {\"audio\":\"output_1494497859133929.wav\", \"gt\":\"47232\"},\n",
    "  {\"audio\":\"output_1494497882023238.wav\", \"gt\":\"93916\"},\n",
    "  {\"audio\":\"output_1494497934197222.wav\", \"gt\":\"24001\"}]''') \n",
    "    \n",
    "    list1 = []\n",
    "    \n",
    "    for first, second in zip(items[0:7], items[7:]):    \n",
    "        stiched_result = AudioSegment.empty()\n",
    "\n",
    "        c1_source_data = \"Test_Data\\\\v1\\\\c1\\\\Google_Captcha_Demo_5_CHAR\\\\\"\n",
    "        \n",
    "        c1_output_data = \"Test_Data\\\\v3_2\\\\c1\\\\\"\n",
    "        \n",
    "        audio = AudioSegment.from_file(c1_source_data + first[\"audio\"], format=\"wav\")\n",
    "        stiched_result += audio\n",
    "        audio = AudioSegment.from_file(c1_source_data + second[\"audio\"], format=\"wav\")\n",
    "        stiched_result += audio\n",
    "        \n",
    "        gt = first[\"gt\"] + second[\"gt\"]\n",
    "        \n",
    "        list1.append({\"audio\" : first[\"audio\"], \"gt\" : gt})\n",
    "        \n",
    "        \n",
    "        # stiched_result.export(c1_output_data + first[\"audio\"], \"wav\")\n",
    "    print(str(list1))\n",
    "\n",
    "stich_audio_alternate_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_filtered_aname_file(file_text, data_version, captcha_type):\n",
    "\n",
    "    audio_name_list = []\n",
    "   \n",
    "    for audio_file in file_text.split(\"\\n\"):\n",
    "        audio_name_list.append({\"audio\" : audio_file.strip()})\n",
    "\n",
    "    audio_folder = \"Test_Data/v\" + data_version + \"/audioname\"\n",
    "    os.makedirs(audio_folder, exist_ok = True)\n",
    "    json.dump(audio_name_list, open(os.path.join(audio_folder, \"aname\" + captcha_type + \".json\"), \"w\"))\n",
    "    \n",
    "    \n",
    "create_filtered_aname_file('''American_Civil_War_chunk_54_1497156637776667_count_0_noise_28_noise_type_White.wav\n",
    "American_revolution_lecture_chunk_107_1497534345207332_count_2_noise_23_noise_type_White.wav\n",
    "American_revolution_lecture_chunk_47_1497156637776667_count_3_noise_15_noise_type_White.wav\n",
    "FinneginsWake_chunk_129_1499080254532628_count_0_noise_7_noise_type_White.wav\n",
    "Google_IO_2017_chunk_196_1497534345207332_count_1_noise_19_noise_type_White.wav\n",
    "Google_IO_2017_chunk_32_1497156637776667_count_0_noise_23_noise_type_White.wav\n",
    "Google_IO_2017_chunk_96_1497156637776667_count_0_noise_18_noise_type_White.wav\n",
    "History_4A_Fall_2007_UC_Berkeley_Lecture_24_Monarchy_at_Rome_The_Age_of_Augustus_20476_chunk_111_1499080254532628_count_0_noise_0_noise_type_White.wav\n",
    "History_4A_Fall_2007_UC_Berkeley_Lecture_24_Monarchy_at_Rome_The_Age_of_Augustus_20476_chunk_129_1499080254532628_count_0_noise_0_noise_type_White.wav\n",
    "Mcluhan-Mckenna_1_chunk_27_1499080254532628_count_1_noise_26_noise_type_White.wav\n",
    "Nikola_Tesla_chunk_15_1497534345207332_count_0_noise_22_noise_type_White.wav\n",
    "Nikola_Tesla_chunk_30_1497156637776667_count_1_noise_7_noise_type_White.wav\n",
    "Shakespeare_chunk_38_1497156637776667_count_0_noise_23_noise_type_White.wav\n",
    "Shakespeare_chunk_60_1497156637776667_count_0_noise_10_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations02-16_chunk_58_1499080254532628_count_0_noise_14_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations04-16_chunk_57_1499080254532628_count_0_noise_25_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations06-16_chunk_63_1499080254532628_count_0_noise_21_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations06-16_chunk_97_1499080254532628_count_0_noise_13_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations08-16_chunk_21_1499080254532628_count_0_noise_0_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations08-16_chunk_3_1499080254532628_count_1_noise_17_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations08-16_chunk_41_1499080254532628_count_0_noise_9_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations08-16_chunk_82_1499080254532628_count_0_noise_6_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations08-16_chunk_82_1499080254532628_count_1_noise_26_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations09-16_chunk_63_1499080254532628_count_0_noise_11_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations09-16_chunk_64_1499080254532628_count_0_noise_7_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations10-16_chunk_14_1499080254532628_count_0_noise_13_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations10-16_chunk_14_1499080254532628_count_1_noise_19_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations12-16_chunk_63_1499080254532628_count_0_noise_29_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations12-16_chunk_64_1499080254532628_count_0_noise_18_noise_type_White.wav\n",
    "TerenceMckenna-TrueHallucinations15-16_chunk_46_1499080254532628_count_0_noise_31_noise_type_White.wav\n",
    "TheVoynichManuscript_chunk_117_1499080254532628_count_1_noise_0_noise_type_White.wav\n",
    "Western_Philosophy_chunk_58_1497534345207332_count_0_noise_15_noise_type_White.wav\n",
    "Yoshua_Bengio_chunk_59_1497156637776667_count_1_noise_0_noise_type_White.wav''', \"3_3\", \"4\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
